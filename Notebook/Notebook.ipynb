{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key=os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    api_key = api_key,\n",
    "    model=\"gemini-2.0-flash\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"tell me a joke\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(r\"D:\\JMM Internship\\M7 - Generative ai\\Task 2\\Flask RAG App\\DATA\\Zabih_Resume-6_1_1.pdf\")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2016', 'creator': 'Microsoft® Word 2016', 'creationdate': '2024-11-12T18:53:55+05:00', 'author': 'Zabih', 'moddate': '2024-11-12T18:53:55+05:00', 'source': 'Zabih_Resume.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='Zabihullah \\n03190904793          Zabihullah18381@gmail.com          GitHub          LinkedIn          Kaggle          Portfolio \\n \\n \\nEducation \\n \\nBachelor of Science in Software Engineering \\nAbasyn University Peshawar: CGPA 3.3 \\nYear of Graduation: 2024 \\nSummery \\n \\nAI and machine learning engineer with nearly one year of hands-on experience in developing intelligent applications. Successfully \\ndeveloped AI chatbots, predictive models, and web applications using advanced technologies like Langchain and Fastapi. Skilled in Python, \\ndata analysis, and deploying AI-driven solutions to enhance software capabilities. \\n \\nWork Experience \\nDataWars.io                                                                            Remote  \\nAi Reasearcher                                                Sep 2024 – Current \\n• Conducted research on advanced RAG techniques and chunking strategies, focusing on retrieval optimization. \\n• Developed Python scripts for efficient text chunking and vector-based retrieval using Langchain and OpenAI embeddings. \\n• Evaluated RAG model performance through metrics such as context precision, recall, and faithfulness to ensure high-quality \\nretrieval results. \\nIntelligent Solution                                                                                         Remote  \\nML/AI  Intern             Aug 2024 – Oct 2024 \\n• Built Ai Chatbot and API using Fastapi, Elasticsearch, Langchain and Qwen2 model with 98% accuracy. \\n• Develop Projects from design to deployment. \\n• Conducted research on various AI models and techniques, including Retrieval-Augmented Generation (RAG), to improve model \\naccuracy. \\n• Assisted in developing AI-driven solutions that enhanced software capabilities through advanced machine learning models and \\nautomation for multiple projects. \\n• Developed AI applications by integrating cutting-edge technologies, leading to a significant increase in client satisfaction and \\ninnovation in the industry. \\nKairiz Cyber Security                                                                          Remote  \\nArtificial intelligence Intern                               July 2024 – Aug 2024 \\n• Worked on end-to-end machine learning project. Perform clearing data, feature engineering, model building. \\n• Received mentorship from senior AI engineers on chatbot development, Agile methodologies, CI/CD, and \\nmicroservices patterns, building a robust technical foundation. \\nProjects \\n \\nCustom Chatbot using Langchain  \\nCreated a chatbot application utilizing website content to provide users with specific information queries. \\nYouTube Comment Sentiment Analysis \\nCreated a Flask app to analyze YouTube comments, classifying them as positive, negative, or neutral. \\nChat with Multiple PDFs using Gemini \\nDeveloped a Streamlit app allowing users to chat with PDF documents using the Gemini conversational AI model. \\nKeyboard Auto Suggestion App \\nCreated a Streamlit web app providing real-time word suggestions and autocorrection based on a preloaded text corpus. \\nFlower Classification Web App \\nDeveloped a Django web application using a Random Forest Classifier to predict the species of an Iris flower based on its dimensions. \\nStudent Performance Indicator \\nImplemented a machine learning pipeline for predicting student marks and developed a Flask web application with a user-friendly \\ninterface. \\nCertificates \\n \\n• Artificial Intelligence \\nXeven Solutions | September 2023 | Certificate Link \\n• Problem Solving (Python) \\nHacker Rank | July 2023 | Certificate Link \\n• Python Basic \\nHacker Rank | July 2023 | Certificate Link \\nSkills Summery \\n \\n• Python \\n• Scikit-learn \\n• Keras, TensorFlow, Pytorch \\n• Soft Skills: Time Management, Communication, \\nLeadership, Flexibility, Teamwork, Decision Making \\n• Data Manipulation with Pandas \\n• Data Analysis with NumPy \\n• Llamindex \\n• Fastapi \\n• CI/CD with Git \\n• Langchain \\n• Rag \\n• Large Language Model: Gemini pro, OpenAI models \\n(GPT3, GPT4), llam3, mistral')]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(google_api_key=api_key, model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting `Weaviate` vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "weaviate_api_key = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "weaviate_url = os.getenv(\"WEAVIATE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "\n",
    "\n",
    "vector_db = WeaviateVectorStore.from_documents(docs, embeddings, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vector_db.similarity_search(\"who is Zabihullah\", k=3)[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template= \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "page_content='Zabihullah \n",
      "03190904793          Zabihullah18381@gmail.com          GitHub          LinkedIn          Kaggle          Portfolio \n",
      " \n",
      " \n",
      "Education \n",
      " \n",
      "Bachelor of Science in Software Engineering \n",
      "Abasyn University Peshawar: CGPA 3.3 \n",
      "Year of Graduation: 2024 \n",
      "Summery \n",
      " \n",
      "AI and machine learning engineer with nearly one year of hands-on experience in developing intelligent applications. Successfully' metadata={'page_label': '1', 'creationdate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'source': 'Zabih_Resume.pdf', 'moddate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'creator': 'Microsoft® Word 2016', 'total_pages': 1.0, 'producer': 'Microsoft® Word 2016', 'page': 0.0, 'author': 'Zabih'}\n",
      "________________________________________________________________________________\n",
      "page_content='automation for multiple projects. \n",
      "• Developed AI applications by integrating cutting-edge technologies, leading to a significant increase in client satisfaction and \n",
      "innovation in the industry. \n",
      "Kairiz Cyber Security                                                                          Remote  \n",
      "Artificial intelligence Intern                               July 2024 – Aug 2024 \n",
      "• Worked on end-to-end machine learning project. Perform clearing data, feature engineering, model building.' metadata={'creator': 'Microsoft® Word 2016', 'total_pages': 1.0, 'source': 'Zabih_Resume.pdf', 'moddate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'creationdate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'page_label': '1', 'producer': 'Microsoft® Word 2016', 'page': 0.0, 'author': 'Zabih'}\n",
      "________________________________________________________________________________\n",
      "page_content='developed AI chatbots, predictive models, and web applications using advanced technologies like Langchain and Fastapi. Skilled in Python, \n",
      "data analysis, and deploying AI-driven solutions to enhance software capabilities. \n",
      " \n",
      "Work Experience \n",
      "DataWars.io                                                                            Remote  \n",
      "Ai Reasearcher                                                Sep 2024 – Current' metadata={'creator': 'Microsoft® Word 2016', 'total_pages': 1.0, 'source': 'Zabih_Resume.pdf', 'moddate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'page_label': '1', 'creationdate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'producer': 'Microsoft® Word 2016', 'page': 0.0, 'author': 'Zabih'}\n",
      "________________________________________________________________________________\n",
      "page_content='• Conducted research on advanced RAG techniques and chunking strategies, focusing on retrieval optimization. \n",
      "• Developed Python scripts for efficient text chunking and vector-based retrieval using Langchain and OpenAI embeddings. \n",
      "• Evaluated RAG model performance through metrics such as context precision, recall, and faithfulness to ensure high-quality \n",
      "retrieval results. \n",
      "Intelligent Solution                                                                                         Remote' metadata={'page_label': '1', 'creationdate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'source': 'Zabih_Resume.pdf', 'moddate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'creator': 'Microsoft® Word 2016', 'total_pages': 1.0, 'producer': 'Microsoft® Word 2016', 'page': 0.0, 'author': 'Zabih'}\n",
      "________________________________________________________________________________\n",
      "page_content='• Received mentorship from senior AI engineers on chatbot development, Agile methodologies, CI/CD, and \n",
      "microservices patterns, building a robust technical foundation. \n",
      "Projects \n",
      " \n",
      "Custom Chatbot using Langchain  \n",
      "Created a chatbot application utilizing website content to provide users with specific information queries. \n",
      "YouTube Comment Sentiment Analysis \n",
      "Created a Flask app to analyze YouTube comments, classifying them as positive, negative, or neutral. \n",
      "Chat with Multiple PDFs using Gemini' metadata={'page_label': '1', 'total_pages': 1.0, 'source': 'Zabih_Resume.pdf', 'moddate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'creator': 'Microsoft® Word 2016', 'creationdate': datetime.datetime(2024, 11, 12, 18, 53, 55, tzinfo=datetime.timezone(datetime.timedelta(seconds=18000))), 'producer': 'Microsoft® Word 2016', 'page': 0.0, 'author': 'Zabih'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = retriever.invoke(\"who is zabih\")\n",
    "for i in response:\n",
    "    print(\"_\"*80)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zabihullah is an AI and machine learning engineer with nearly one year of hands-on experience in developing intelligent applications. He is a graduate of Abasyn University Peshawar with a Bachelor of Science in Software Engineering and a CGPA of 3.3. He has experience as an AI Researcher at DataWars.io and as an Artificial Intelligence Intern at Kairiz Cyber Security.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"Who is Zabih?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zabih\\anaconda3\\Lib\\site-packages\\weaviate\\warnings.py:340: UserWarning: Con006: You're using the sync client in an async context. This usage is discouraged to avoid blocking your async event loop with sync I/O calls.\n",
      "            We encourage you to update your code to use the async client instead when running inside async def functions!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "# Best practice: store your credentials in environment variables\n",
    "weaviate_url = os.environ[\"WEAVIATE_URL\"]\n",
    "weaviate_api_key = os.environ[\"WEAVIATE_API_KEY\"]\n",
    "\n",
    "# Connect to Weaviate Cloud\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=weaviate_url,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key),\n",
    ")\n",
    "\n",
    "print(client.is_ready())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
